# Gold from Bronze: Training a Stable Affective Neural Network by Refining Noisy LLM-Generated Data

# Abstract
Affective computing systems traditionally rely on rule-based engines or large pre-defined datasets, both of which limit adaptability, scalability, and emotional nuance. In this work, I propose a neural method for modeling stateful emotion transitions using synthetic hormone-inspired data generated via large language models (LLMs). The objective is to learn a continuous, physiologically-motivated function mapping social-emotional inputs to next-state hormone vectors without ground-truth physiological data.
I present a teacher‚Äìstudent framework where a curated prompt induces an LLM (Gemini 2.5 Flash) to act as a pseudo-expert in affective reasoning, generating 400 initial samples and 20 hand-crafted edge-case samples. After feature cleanup and dataset expansion to ~1000 samples, I train a compact feedforward neural network to map (hormones, user intent logits) ‚Üí next hormones.
Through a sequence of ablations, I identify the core challenges: (1) a ‚Äúdying ReLU‚Äù failure mode causing convergence plateaus at MAE ‚âà 9, (2) high-volatility synthetic labels that penalize stable predictions, and (3) output activation saturation leading to a zero-bias collapse near the lower bound. I systematically resolve these issues by (i) replacing ReLU with ELU, (ii) removing noisy engineered features, (iii) augmenting with targeted edge-case samples, (iv) applying learning-rate decay, and (v) implementing a Parametric Bounded Linear Activation (PBLA), a learnable hard-sigmoid output function.
The final model achieves 5.60 training MAE and 5.25 test MAE, with Test < Train indicating strong regularization (notably due to dropout deactivation during inference). I validate the model using a deterministic physiological mapping layer, demonstrating that the network effectively learns complex behaviors such as emotional inertia, de-escalation, and stability filtering. Error analysis reveals that most high test errors arise not from model failures but from intentional rejections of implausibly ‚Äúspiky‚Äù labels generated by the teacher model‚Äîa phenomenon I call Gold from Bronze, where a model trained on noisy synthetic signals learns a smoother, more coherent emotional logic than its labels.
This work demonstrates that small neural networks can learn complex affective state-transition dynamics from noisy synthetic data when guided by principled activation design, data-centric iteration, and tailored regularization.

# Conclusion
I have demonstrated a compact and effective affective state-transition model trained entirely on synthetic hormone-inspired data created using a teacher LLM. Through systematic experimentation, architectural changes, data-centric iteration, and a novel output activation (PBLA), I reduced MAE from ~9.0 to ~5.25. Crucially, qualitative validation via a deterministic physiological mapping layer confirms that this numerical improvement corresponds to interpretable, socially intelligent behavior, successfully distinguishing between transient high-excitement states and stable bonding dynamics.
Beyond performance improvement, this work provides principled methods for training models on inherently noisy, synthetic, soft-labeled data.
The approach is suitable for real-time conversational agents, affective simulators, and reinforcement-learning agents requiring internal emotional states.

## üöÄ How to Reproduce Results

To replicate the findings of the paper (Test MAE ~5.25) and verify the "Gold from Bronze" phenomenon, follow these steps.

### 1. Setup Environment
Clone the repository and install the required dependencies.

```bash
git clone [https://github.com/Shivansh-Game/gold-from-bronze.git](https://github.com/Shivansh-Game/gold-from-bronze.git)
cd gold-from-bronze

# Install core dependencies
pip install torch pandas tqdm google-generativeai scikit-learn
```
2. Reproduce the Training Run
The repository comes pre-loaded with the finalized 1,000-sample dataset in the datasets/ folder. To train the model using the optimized configuration (AdamW, PBLA, Dropout=0.45):
```bash
python state_manager_model.py
```
Expected Output:

The script will initialize the FNN with the [320] hidden layer configuration.

It will run for 10,000 epochs using a multi-step learning rate decay.

Final Result: You should observe a Training L1 Loss of ~5.6 and a Test MAE of ~5.25, confirming the Test < Train stability finding.

3. (Optional) Re-Generate Synthetic Data
If you wish to reproduce the dataset generation process using the Teacher-Student pipeline:

Set your Google Gemini API key:

```bash

export GOOGLE_API_KEY="your_api_key_here"
# Or set it in your environment variables manually
```
Run the teacher distillation script:

```bash
python dataset_generator.py
```
Generate the edge-case augmentation samples:

```bash
python edge_case_data_gen.py
```

# References 

Clevert, D. A., Unterthiner, T., & Hochreiter, S. (2016). Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs). In Proceedings of the 4th International Conference on Learning Representations (ICLR).
Gao, Q., He, L., & Chen, Z. (2021). A Survey on Dialogue State Tracking. arXiv:2105.02388.
Gemini Team, Google. (2025). Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities. arXiv:2507.06261.
Kingma, D. P., & Ba, J. (2014). Adam: A Method for Stochastic Optimization. arXiv:1412.6980.
Lu, L., Shin, Y., Su, Y., & Karniadakis, G. E. (2019). Dying ReLU and Initialization: Theory and Numerical Examples. arXiv:1903.06733.
Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., ... & Chintala, S. (2019). PyTorch: An Imperative Style, High-Performance Deep Learning Library. Advances in Neural Information Processing Systems (NeurIPS), 32.
Rashkin, H., Smith, E. M., Li, M., & Boureau, Y. L. (2019). Towards Empathetic Open-domain Conversation Models: A New Benchmark and Dataset. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL).
Wang, Y., Kaddour, J., & Winstanley, L. (2024). Large Language Models as Data Augmenters. In Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL).

